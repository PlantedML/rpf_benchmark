---
title: "RPF Classification Benchmark Results"
author: "Lukas"
date: now
date-format: "YYYY-MM-DD HH:mm z"
date-modified: last-modified
format: 
  html:
    code-fold: true
    fig-align: center
    toc: true
  pdf: 
    documentclass: article
    fig-align: center
    toc: true
    date: now
    keep-tex: true
    knitr: 
      opts_chunk: 
        echo: false
        fig.pos: H
    include-in-header: 
      - \usepackage{float}
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| message: false
#| warning: false
library(ggplot2)
library(mlr3)
#library(mlr3batchmark)
#library(mlr3viz)
#library(mlr3tuning)
library(data.table)
library(dplyr)
library(kableExtra)

# measures for evaluation
msr_binary <- msrs(c("classif.auc", "classif.bbrier"))
msr_multiclass <- msrs(c("classif.mauc_aunp", "classif.mbrier"))

# Load task metadata
task_summary <- as.data.table(readRDS("task_summary.rds"))

# benchmark results + cleanup
bmr_binary <- readRDS("data/bmr-binary-auc.rds")
bmr_multiclass <- readRDS("data/bmr-multiclass-auc.rds")

cleanup_bmr <- function(bmr, eval_measures, task_summary) {
  # Evaluate overall
  aggr <- bmr$aggregate(measures = eval_measures)
  # rename learners for convenience
  aggr[, learner_name := gsub("\\.tuned", "", gsub("(encode\\.)?classif\\.", "", learner_id))]
  
  # long version for plotting over multiple measures
  aggr_long <- melt(aggr, measure.vars = mlr3misc::ids(eval_measures), variable.name = "measure")
  aggr_long[, measure := gsub("^classif\\.", "", measure)]
  
  # evaluate all resampling folds, cleanup names etc
  scores <- bmr$score(measures = eval_measures)
  scores[, learner_name := gsub("\\.tuned", "", gsub("(encode\\.)?classif\\.", "", learner_id))]
  # Remove unneeded columns
  scores[, c("task", "learner", "resampling", "resampling_id") := NULL]
  # Join task metadata
  scores <- scores[task_summary[, -c("task_id")], on = c("task_id" = "task_name_full"), nomatch = 0]
  
  # Sort task_name levels by n * p from task_summary
  scores[, task_name := factor(task_name, levels = task_summary$task_name)]
  scores_long <- melt(scores, measure.vars = mlr3misc::ids(eval_measures), variable.name = "measure")
  scores_long[, measure := gsub("^classif\\.", "", measure)]

  list(aggr = aggr, aggr_long = aggr_long, scores = scores, scores_long = scores_long)
}

tmp1 <- cleanup_bmr(bmr_binary, msr_binary, task_summary)

aggr_binary <- tmp1$aggr
aggr_binary_long <- tmp1$aggr_long
scores_binary <- tmp1$scores
scores_binary_long <- tmp1$scores_long

tmp2 <- cleanup_bmr(bmr_multiclass, msr_multiclass, task_summary)

aggr_multiclass <- tmp2$aggr
aggr_multiclass_long <- tmp2$aggr_long
scores_multiclass <- tmp2$scores
scores_multiclass_long <- tmp2$scores_long

rm(tmp1, tmp2)

# Tuning results cleanup 
cleanup_tuning_results <- function(results, task_summary) {
  results <- copy(results)
  
  # merge with task summary for task metadata/names
  results <- results[task_summary[, -c("task_id")], on = c("task_id" = "task_name_full"), nomatch = 0]
  
  # Cleanup learner names
  results[, learner_name := gsub("\\.tuned", "", gsub("(encode\\.)?classif\\.", "", learner_id))]
  
  # Reconstruct max_interaction from _ratio, using p from task_summary
  # taking into account the max_interaction_limit of 20
  results[, max_interaction := ifelse(learner_id == "classif.rpf_fixmax.tuned", 2, pmax(ceiling(max_interaction_ratio * pmin(p, 30)), 1))]
  
  results[, task_name := factor(task_name, levels = task_summary$task_name)]
  
  results[]
}

tuning_results_rpf_binary_auc <- cleanup_tuning_results(readRDS("data/tuning_results_rpf-binary-auc.rds"), task_summary = task_summary)
tuning_results_rpf_multiclass_auc <- cleanup_tuning_results(readRDS("data/tuning_results_rpf-multiclass-auc.rds"), task_summary = task_summary)

# Define learner colors for somewhat identifiable plots
learner_cols <- c(
  "ranger" = "#2171B5",
  "xgboost" = "#3BA99C",
  "xgboost_fixdepth" = "#256A62",
  "rpf" = "#F73098",
  "rpf_fixmax" = "#CA1694"
)

set.seed(3) # Only for jitterdodge consistency
```


## Binary Classification

- Tuning on: [AUC](https://mlr3.mlr-org.com/reference/mlr_measures_classif.auc.html)
- Evaluation on:
    -  [AUC](https://mlr3.mlr-org.com/reference/mlr_measures_classif.auc.html)
    -  [Binary Brier](https://mlr3.mlr-org.com/reference/mlr_measures_classif.bbrier.html)

### Tasks

[OpenML CC18](https://www.openml.org/search?type=study&study_type=task&id=99) tasks with:

- Binary target
- No missing values
- $n \cdot p \leq 10^5$

```{r binary-tasks}
task_summary |>
  filter(twoclass & dim <= 1e5) |>
  select(task_id, task_name, n, p, dim) |>
  kbl(
    caption = "Selected OpenML CC18 tasks for binary classification",
    col.names = c("ID", "Task", "n", "p", "np"),
    booktabs = TRUE
  ) |>
  kable_styling()
```


### Aggregated Results

#### Boxplot

```{r binary-aggregated}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

aggr_binary_long |>
  mutate(
    measure = case_when(
      measure == "auc" ~ "AUC",
      measure == "bbrier" ~ "Brier Score"
    )
  ) |>
  ggplot(aes(x = learner_name, y = value, fill = learner_name)) +
    facet_wrap(vars(measure), ncol = 2, scales = "free_y") +
    geom_boxplot(alpha = .5) +
    geom_point(position = position_jitterdodge(dodge.width = .25)) +
    scale_y_continuous(labels = scales::percent) +
    #scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
    #coord_cartesian(ylim = c(0, 1)) +
    #coord_flip() +
    scale_fill_manual(values = learner_cols, guide = "none") +
    labs(
      title = "Binary Classification: Aggregated scores over all tasks",
      x = NULL, y = "Score"
    ) +
    theme_minimal(base_size = 14)
```

#### Table

```{r binary-aggregated-table}
# column: screen-inset-shaded
aggr_binary_long |>
  group_by(learner_name, measure) |>
  summarize(
    mean = mean(value),
    median = median(value),
    sd = sd(value),
    q25 = quantile(value, .25),
    q75 = quantile(value, .75),
    .groups = "drop"
  ) |>
  mutate(across(where(is.numeric), \(x) round(100 * x, 1))) |>
  mutate(
    mean = glue::glue("{mean} [{sd}]"),
    median = glue::glue("{median} [{q25}; {q75}]")
  ) |>
  select(-sd, -q25, -q75) |>
  tidyr::pivot_wider(names_from = measure, names_sep = "_", values_from = mean:median) |>
  select(learner_name, ends_with("auc"), ends_with("brier")) |>
  kbl(
    col.names = c("Learner", rep(c("Mean [SD]", "Median [q25; q75]"), 2)),
    booktabs = TRUE
  ) |>
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position")) |>
  add_header_above(header = c(" " = 1, "AUC (%)" = 2, "Brier Score (%)" = 2)) |>
  column_spec(1, "4cm") |>
  column_spec(2, "2.3cm") |>
  column_spec(3, "3cm") |>
  column_spec(4, "2.3cm") |>
  column_spec(5, "3cm")
```


### Results per Task

```{r binary-per-task-auc}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_binary, aes(x = learner_name, y = classif.auc, fill = learner_name)) +
  facet_wrap(vars(task_name), ncol = 4) +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    x = "Learner", y = "AUC (%)"
  ) +
  theme_minimal()
```


```{r binary-per-task-auc-flip}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_binary, aes(y = learner_name, x = classif.auc, fill = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Binary classification scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    y = "Learner", x = "AUC (%)"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm")
  )
```


```{r binary-per-task-brier}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_binary, aes(y = learner_name, x = classif.bbrier, fill = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Binary classification scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    y = "Learner", x = "Brier Score (%)"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm")
  )
```

### Tuning Results

Showing best performing parameter combinations of the inner folds, e.g. the parameters that "won".
One plot per hyperparameter, with performance on y-axis.

Note that `max_interaction` is tuned by tuning `max_interaction_ratio` within [0, 1] and then calculating

$$min(max(\mathrm{max\_interaction\_ratio} \cdot p), 30)$$
to effectively tune `max_interaction` within 1 and $p$ or 30, whichever is lower. 
This is not ideal since multiple values for `max_interaction_ratio` could result in the same value for `max_interaction` for large $p$, but it's a compromise.

```{r binary-tuning-resutls-auc}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

tuning_results_rpf_binary_auc |>
  ggplot(aes(x = splits, y = classif.auc, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_binary_auc |>
  mutate(task_name = glue::glue("{task_name} (p={p})")) |>
  ggplot(aes(x = max_interaction, y = classif.auc, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_binary_auc |>
  ggplot(aes(x = loss, y = classif.auc, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_binary_auc |>
  ggplot(aes(x = split_try, y = classif.auc, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_binary_auc |>
  ggplot(aes(x = t_try, y = classif.auc, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )
```


## Multiclass Classification

- Tuning on: [AUNP](https://mlr3.mlr-org.com/reference/mlr_measures_classif.mauc_aunp.html)
- Evaluation on:
    -  [AUNP](https://mlr3.mlr-org.com/reference/mlr_measures_classif.mauc_aunp.html)
    -  [Multiclass Brier](https://mlr3.mlr-org.com/reference/mlr_measures_classif.mbrier.html)

### Tasks

[OpenML CC18](https://www.openml.org/search?type=study&study_type=task&id=99) tasks with:

- Multiclass target
- No missing values
- $n \cdot p \leq 10^5$

```{r multiclass-tasks}
task_summary |>
  filter(!twoclass & dim <= 1e5) |>
  select(task_id, task_name, n, p, dim) |>
  kbl(
    caption = "Selected OpenML CC18 tasks for multiclass classification",
    col.names = c("ID", "Task", "n", "p", "np"),
    booktabs = TRUE
  ) |>
  kable_styling()
```

### Aggregated Results

#### Boxplot

```{r multiclass-aggregated}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

aggr_multiclass_long |>
  mutate(
    measure = case_when(
      measure == "mauc_aunp" ~ "AUNP",
      measure == "mbrier" ~ "Multiclass Brier Score"
    )
  ) |>
  ggplot(aes(x = learner_name, y = value, fill = learner_name)) +
    facet_wrap(vars(measure), ncol = 2, scales = "free") +
    geom_boxplot(alpha = .5) +
    geom_point(position = position_jitterdodge(dodge.width = .25)) +
    scale_y_continuous(labels = scales::percent) +
    #scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
    #coord_cartesian(ylim = c(0, 1)) +
    #coord_flip() +
    scale_fill_manual(values = learner_cols, guide = "none") +
    labs(
      title = "Multiclass Classification: Aggregated scores over all tasks",
      x = NULL, y = "Score"
    ) +
    theme_minimal(base_size = 14)
```

#### Table

```{r multiclass-aggregated-table}
# column: screen-inset-shaded
aggr_multiclass_long |>
  group_by(learner_name, measure) |>
  summarize(
    mean = mean(value),
    median = median(value),
    sd = sd(value),
    q25 = quantile(value, .25),
    q75 = quantile(value, .75),
    .groups = "drop"
  ) |>
  mutate(across(where(is.numeric), \(x) round(100 * x, 1))) |>
  mutate(
    mean = glue::glue("{mean} [{sd}]"),
    median = glue::glue("{median} [{q25}; {q75}]")
  ) |>
  select(-sd, -q25, -q75) |>
  tidyr::pivot_wider(names_from = measure, names_sep = "_", values_from = mean:median) |>
  select(learner_name, ends_with("aunp"), ends_with("brier")) |>
  kbl(
    col.names = c("Learner", rep(c("Mean [SD]", "Median [q25; q75]"), 2)),
    booktabs = TRUE
  ) |>
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position")) |>
  add_header_above(header = c(" " = 1, "AUNP (%)" = 2, "Multiclass Brier Score (%)" = 2)) |>
  column_spec(1, "4cm") |>
  column_spec(2, "2.3cm") |>
  column_spec(3, "3cm") |>
  column_spec(4, "2.3cm") |>
  column_spec(5, "3cm")
```


### Results per Task

```{r multiclass-per-task-auc}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_multiclass, aes(x = learner_name, y = classif.mauc_aunp, fill = learner_name)) +
  facet_wrap(vars(task_name), ncol = 4, scales = "free_y") +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Multiclass scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    x = "Learner", y = "AUC (%)"
  ) +
  theme_minimal()
```


```{r multiclass-per-task-auc-flip}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_multiclass, aes(y = learner_name, x = classif.mauc_aunp, fill = learner_name)) +
  facet_wrap(vars(task_name), scales = "free_x") +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Multiclass scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    y = "Learner", x = "AUC (%)"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm")
  )
```


```{r multiclass-per-task-brier}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

ggplot(scores_multiclass, aes(y = learner_name, x = classif.mbrier, fill = learner_name)) +
  facet_wrap(vars(task_name), scales = "free") +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::percent) +
  labs(
    title = "Scores per task",
    subtitle = "Tasks ordered by n * p, decreasing",
    y = "Learner", x = "Brier Score (%)"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm")
  )
```

### Tuning Results

Showing best performing parameter combinations of the inner folds, e.g. the parameters that "won".
One plot per hyperparameter, with performance on y-axis.

Note that `max_interaction` is tuned by tuning `max_interaction_ratio` within [0, 1] and then calculating

$$min(max(\mathrm{max\_interaction\_ratio} \cdot p), 30)$$
to effectively tune `max_interaction` within 1 and $p$ or 30, whichever is lower. 
This is not ideal since multiple values for `max_interaction_ratio` could result in the same value for `max_interaction` for large $p$, but it's a compromise.

```{r multiclass-tuning-resutls-auc}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

tuning_results_rpf_multiclass_auc |>
  ggplot(aes(x = splits, y = classif.mauc_aunp, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_multiclass_auc |>
  mutate(task_name = glue::glue("{task_name} (p={p})")) |>
  ggplot(aes(x = max_interaction, y = classif.mauc_aunp, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_multiclass_auc |>
  ggplot(aes(x = loss, y = classif.mauc_aunp, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_multiclass_auc |>
  ggplot(aes(x = split_try, y = classif.mauc_aunp, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )

tuning_results_rpf_multiclass_auc |>
  ggplot(aes(x = t_try, y = classif.mauc_aunp, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Binary classifification tuning results",
    subtitle = "Tuned on AUC"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )
```
